<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>操作系统-进程与线程</title>
    <link href="/2025/10/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"/>
    <url>/2025/10/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><h2 id="一、进程的状态"><a href="#一、进程的状态" class="headerlink" title="一、进程的状态"></a>一、进程的状态</h2><p>三种基本状态：<strong>运行状态，就绪状态，阻塞状态</strong></p><p><strong>此外还有创建，结束状态，挂起状态。</strong></p><p>在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。这就是<strong>挂起状态</strong>。</p><p>挂起状态可以分为两种：</p><p>阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；</p><p>就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；</p><h2 id="二、进程控制块（process-control-block，PCB）"><a href="#二、进程控制块（process-control-block，PCB）" class="headerlink" title="二、进程控制块（process control block，PCB）"></a>二、进程控制块（process control block，PCB）</h2><p><strong>描述进程的数据结构。切换进程时，<strong><strong>PCB</strong></strong>还会保存<strong><strong>cpu</strong></strong>状态。</strong></p><h3 id="PCB包含信息："><a href="#PCB包含信息：" class="headerlink" title="PCB包含信息："></a>PCB包含信息：</h3><h4 id="1-、进程描述信息："><a href="#1-、进程描述信息：" class="headerlink" title="1**、进程描述信息："></a><em>1**、进程描述信息：</em></h4><p><strong>进程标识符</strong>：标识各个进程，每个进程都有一个并且唯一的标识符；</p><p><strong>用户标识符</strong>：进程归属的用户，用户标识符主要为共享和保护服务；</p><h4 id="2-、进程控制和管理信息："><a href="#2-、进程控制和管理信息：" class="headerlink" title="2**、进程控制和管理信息："></a><em>2**、进程控制和管理信息：</em></h4><p><strong>进程当前状态</strong>，如 new、ready、running、waiting 或 blocked 等；</p><p><strong>进程优先级</strong>：进程抢占 CPU 时的优先级；</p><h4 id="3-、资源分配清单："><a href="#3-、资源分配清单：" class="headerlink" title="3**、资源分配清单："></a><em>3**、资源分配清单：</em></h4><p><strong>有关内存地址空间或虚拟地址空间的信息</strong>，所打开文件的列表和所使用的 I&#x2F;O 设备信息。</p><h4 id="4、CPU-相关信息："><a href="#4、CPU-相关信息：" class="headerlink" title="4、CPU 相关信息："></a><em>4<strong>、</strong>CPU</em> <em>相关信息：</em></h4><p><strong>CPU 中各个寄存器的值</strong>，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。</p><p>PCB通过链表的方式进行组织，将具有相同状态的pcb链在一起，组成队列。</p><p>比如具有就绪状态的进程们组成就绪队列。</p><h2 id="三、进程控制"><a href="#三、进程控制" class="headerlink" title="三、进程控制"></a>三、进程控制</h2><h3 id="1、进程创建"><a href="#1、进程创建" class="headerlink" title="1、进程创建"></a>1、进程创建</h3><p>允许一个进程创建另一个进程，允许子进程继承父进程拥有的资源。</p><p>为进程申请一块空白pcb，将该pcb插入就绪队列中。</p><h3 id="2、终止进程："><a href="#2、终止进程：" class="headerlink" title="2、终止进程："></a>2、终止进程：</h3><p>3种终止方式，正常结束，异常结束，外界干预</p><p>子进程被终止，它在父进程继承的资源需归还，父进程被终止，它的子进程会被其他进程收养。</p><h3 id="3、阻塞进程："><a href="#3、阻塞进程：" class="headerlink" title="3、阻塞进程："></a>3、阻塞进程：</h3><p>当一个进程需要等待某一事件完成，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。</p><h3 id="4、唤醒进程："><a href="#4、唤醒进程：" class="headerlink" title="4、唤醒进程："></a>4、唤醒进程：</h3><p>其它进程唤醒阻塞的进程</p><h2 id="四、进程上下文切换"><a href="#四、进程上下文切换" class="headerlink" title="四、进程上下文切换"></a>四、进程上下文切换</h2><p>一个进程切换到另一个进程运行，称为<strong>进程的上下文切换</strong></p><p>CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 CPU 上下文。</p><h3 id="CPU上下文切换："><a href="#CPU上下文切换：" class="headerlink" title="CPU上下文切换："></a>CPU上下文切换：</h3><p>CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。</p><h3 id="进程上下文："><a href="#进程上下文：" class="headerlink" title="进程上下文："></a>进程上下文：</h3><p>进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。（进程上下文包括CPU上下文）</p><p>通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行。</p><h1 id="五、进程通信方式"><a href="#五、进程通信方式" class="headerlink" title="五、进程通信方式"></a>五、进程通信方式</h1><p>1、管道</p><p>2、消息队列</p><p>3、共享内存:共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中</p><p>4、信号量</p><p>5、套接字socket</p><p>6、信号</p><h1 id="线程："><a href="#线程：" class="headerlink" title="线程："></a>线程：</h1><h2 id="一、和进程区别"><a href="#一、和进程区别" class="headerlink" title="一、和进程区别"></a>一、和进程区别</h2><p>相比进程优势：1、并发运行 2、共享相同地址空间</p><p>缺点：当进程中的一个线程崩溃，会导致所属进程所有线程崩溃（仅针对C&#x2F;C++)</p><p>各个线程拥有一套独立的寄存器和栈</p><h2 id="二、线程上下文切换"><a href="#二、线程上下文切换" class="headerlink" title="二、线程上下文切换"></a>二、线程上下文切换</h2><p>当两个线程属于同一进程，线程在<strong>上下文切换</strong>只需保存它的私有数据，比如栈和寄存器，它共享的进程的资源是不需要保存的。</p><p>当它们分属不同进程，则切换的过程和进程上下文切换一样。</p><h2 id="三、线程的实现："><a href="#三、线程的实现：" class="headerlink" title="三、线程的实现："></a>三、线程的实现：</h2><p>1、用户线程：用户空间实现的线程</p><p>2、内核线程：由内核管理的线程</p><p>3、轻量级进程：在内核中支持用户线程</p><h3 id="1、用户线程："><a href="#1、用户线程：" class="headerlink" title="1、用户线程："></a>1、用户线程：</h3><p>操作系统只能看见进程的PCB，看不见用户线程控制块TCB，所以操作系统不参与用户线程的线程管理和调度。线程的创建，终止，同步和调度由用户级线程库函数完成。</p><h3 id="2、内核线程："><a href="#2、内核线程：" class="headerlink" title="2、内核线程："></a>2、内核线程：</h3><p>线程由操作系统管理，TCB放在操作系统中，线程的创建，终止，同步和调度由操作系统负责。</p><p>优点：在一个进程中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程运行</p><h3 id="3、轻量级进程："><a href="#3、轻量级进程：" class="headerlink" title="3、轻量级进程："></a>3、轻量级进程：</h3><p>轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的</p><h2 id="四、进程调度："><a href="#四、进程调度：" class="headerlink" title="四、进程调度："></a>四、进程调度：</h2><p>选择一个进程运行这一功能是在操作系统中完成的，通常称为<strong>调度程序（scheduler）</strong>。</p><p>因为线程才是cpu的调度单位，这里的进程实际指进程的主线程，调度主线程就等于调度了进程</p><h3 id="调度算法分类："><a href="#调度算法分类：" class="headerlink" title="调度算法分类："></a>调度算法分类：</h3><p>1、非抢占式：进程运行直到被阻塞或退出</p><p>2、抢占式：只让进程运行某段时间，称为时间片机制，在时间片末端会发生<strong>时钟中断</strong></p><h3 id="调度原则"><a href="#调度原则" class="headerlink" title="调度原则"></a>调度原则</h3><p><strong>CPU利用率：</strong>调度程序应确保CPU是始终匆忙的状态，这可提高CPU的利用率；<br><strong>系统吞吐量：</strong>吞吐量表示的是单位时间内CPU完成进程的数量，长作业的进程会占用较长的CPU资<br>源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；<br><strong>周转时间：</strong>周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；<br><strong>等待时间：</strong>这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户<br>越不满意；<br><strong>响应时间：</strong>用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度<br>算法好坏的主要标准。</p><h3 id="调度算法："><a href="#调度算法：" class="headerlink" title="调度算法："></a>调度算法：</h3><p><strong>1****、非抢占式的先来先服务（First Come First Serve, FCFS）算法</strong></p><p><strong>2****、最短作业优先（Shortest Job First, SJF）调度算法，</strong>优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。但可能导致长作业一直不被运行</p><p><strong>3****、高响应比优先 （Highest Response Ratio Next, HRRN）调度算法（要求服务时间不可预知，所以根本无法实现）</strong></p><p><strong>4****、时间片轮转（Round Robin, RR）调度算法。使用最广</strong></p><p><strong>5****、最高优先级（Highest Priority First，HPF）调度算法（设置静态或随运行时间变化的优先级）</strong></p><p><strong>6****、多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。</strong>新的进程如果在队列1没运行完，就会进入下一个队列，只有上一个队列为空，下一个队列的进程才会运行</p>]]></content>
    
    
    
    <tags>
      
      <tag>知识分享</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>操作系统-存储器</title>
    <link href="/2025/10/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%AD%98%E5%82%A8%E5%99%A8/"/>
    <url>/2025/10/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%AD%98%E5%82%A8%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="一、层次结构"><a href="#一、层次结构" class="headerlink" title="一、层次结构"></a>一、层次结构</h1><p><strong>图书馆场景</strong>：</p><p>我们可以把 CPU 比喻成我们的大脑，大脑正在思考的东西，就好比 CPU 中的寄存器，</p><p>我们大脑中的记忆，就好比 CPU Cache，CPU Cache 通常会分为 L1、L2、L3 三层，其中 L1 Cache 通常分成「数据缓存」和「指令缓存」，L1 是距离 CPU 最近的，因此它比 L2、L3 的读写速度都快、存储空间都小。我们大脑中短期记忆，就好比 L1 Cache，而长期记忆就好比 L2&#x2F;L3 Cache。</p><p>那我们桌子上的书，就好比内存，我们虽然可以一伸手就可以拿到，但读写速度肯定远慢于寄存器，那图书馆书架上的书，就好比硬盘。</p><p>每层只和相邻的存储介质打交道。</p><h2 id="1、寄存器"><a href="#1、寄存器" class="headerlink" title="1、寄存器"></a>1、寄存器</h2><p>寄存器的数量通常是几十到几百之间，</p><p>32位cpu中大多数寄存器存4字节，64位cpu大多数寄存器存8字节。</p><p>寄存器访问速度非常快，一般要求半个时钟周期内。</p><p><strong>时钟周期（Clock Cycle）</strong>是 CPU 执行指令的最基本时间单位，由 CPU 的时钟信号控制。每个时钟周期内，CPU 可能完成一个或多个基本操作，例如取指令、解码、执行等。</p><h2 id="2、cpu-cache"><a href="#2、cpu-cache" class="headerlink" title="2、cpu cache"></a>2、cpu cache</h2><p>用的是一种叫做<strong>SRAM</strong>（Static Random-Access Memory，静态随机存取存储器） 的芯片，一个bit的数据通常需要6个晶体管。</p><p>1）L1高速缓存，几乎和寄存器一样快，2到4个时钟周期，大小在几十kb到几百KB不等。分成「数据缓存」和「指令缓存」</p><p>2）L2高速缓存，10到20个时钟周期，大小通常几百kb到几MB</p><p>3）L3高速缓存，20到60个时钟周期，大小通常几MB到几十MB</p><p>L1和L2 cache是每个cpu核心独有，而L3 cache是多个cpu核心共享，所以会比前两者大很多。</p><h2 id="3、内存："><a href="#3、内存：" class="headerlink" title="3、内存："></a>3、内存：</h2><p>（大概200到300时钟周期的访问时间。）</p><p>使用的芯片与cpu cache不同，叫作 DRAM （Dynamic Random Access Memory，动态随机存取存储器），一个bit的数据需要一个晶体管和一个电容，因为电容会不断漏电，所以需要不断刷新，数据才不会丢失。所以叫“动态”。</p><h2 id="4、SSD（solid-state-disk）-HDD-hard-disk-drive-硬盘"><a href="#4、SSD（solid-state-disk）-HDD-hard-disk-drive-硬盘" class="headerlink" title="4、SSD（solid-state disk）&#x2F;HDD(hard-disk drive)硬盘"></a>4、SSD（solid-state disk）&#x2F;HDD(hard-disk drive)硬盘</h2><p>内存读写速度大概是SSD的10~1000倍。</p><h2 id="5、cpu-cache内部结构，读取过程"><a href="#5、cpu-cache内部结构，读取过程" class="headerlink" title="5、cpu cache内部结构，读取过程"></a>5、cpu cache内部结构，读取过程</h2><p>Cache line的大小是一个cpu一次载入数据的量，</p><p>比如一个64字节cache line的cpu cache，有一个 int array[100] 的数组，当载入 array[0] 时，由于这个数组元素的大小在内存只占 4 字节，不足 64 字节，CPU 就会顺序加载数组元素到 array[15]，意味着 array[0]~array[15] 数组元素都会被缓存在 CPU Cache 中了。</p><p>无论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache 中找不到数据时，才会去访问内存，并把内存中的数据读入到 Cache 中，CPU 再从 CPU Cache 读取数据。</p><p>一个<strong>内存</strong>的访问地址，包括组标记（应对取模的重复问题），cpu cacheline 索引（哪个cacheline），偏移量(这个cacheline中的哪里)</p><h1 id="二、如何写出让cpu跑得更快的代码（即缓存命中率更高的代码）"><a href="#二、如何写出让cpu跑得更快的代码（即缓存命中率更高的代码）" class="headerlink" title="二、如何写出让cpu跑得更快的代码（即缓存命中率更高的代码）"></a>二、如何写出让cpu跑得更快的代码（即缓存命中率更高的代码）</h1><p>1、L1缓存需要分开看数据缓存和指令缓存的命中率</p><p>1）如何提高<strong>数据缓存</strong>命中率：</p><p>按照内存布局的顺序访问，即访问连续的数据</p><p>2）如何提高<strong>指令缓存</strong>命中率：</p><p><strong>分支预测</strong>：如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，</p><p>就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快。</p><p>2、多核cpu缓存命中率</p><p>因为L1和L2都是每个核心独有，当一个线程在不同核心之间切换，就会降低命中率。</p><p>所以通过将线程绑定在某个cpu核心上可以提高命中率。</p>]]></content>
    
    
    
    <tags>
      
      <tag>知识分享</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>操作系统基础一</title>
    <link href="/2025/10/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E4%B8%80/"/>
    <url>/2025/10/05/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E4%B8%80/</url>
    
    <content type="html"><![CDATA[<h1 id="一、冯洛伊曼模型"><a href="#一、冯洛伊曼模型" class="headerlink" title="一、冯洛伊曼模型"></a>一、冯洛伊曼模型</h1><p>运算器，控制器，存储器，输入，输出</p><h2 id="1、内存："><a href="#1、内存：" class="headerlink" title="1、内存："></a>1、内存：</h2><p>存储数据的基本单位：字节；每字节对应一个内存地址</p><h2 id="2、中央处理器（cpu）"><a href="#2、中央处理器（cpu）" class="headerlink" title="2、中央处理器（cpu）:"></a>2、中央处理器（cpu）:</h2><p>32位，64位cpu的主要区别在一次能计算多少字节数据。</p><p>32位一次计算4字节，64位一次8字节。cpu位宽越大，可以计算的数值就越大</p><p><strong>cpu****内部组件</strong>：寄存器、控制单元、逻辑运算单元</p><p><strong>寄存器种类</strong>：通用寄存器、程序计数器、指令寄存器</p><p>64位和32位<strong>软件</strong>实际代表指令是64还是32位的。</p><h2 id="3、总线："><a href="#3、总线：" class="headerlink" title="3、总线："></a>3、总线：</h2><p>Cpu，内存，其他设备之间的通信。</p><p>分三种：</p><p><strong>地址总线</strong>：用于指定 CPU 将要操作的内存地址；</p><p><strong>数据总线</strong>：用于读写内存的数据；</p><p><strong>控制总线</strong>：用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；</p><p>cpu读写内存数据的执行过程：首先用地址总线指定内存地址，然后控制总线控制是读或写命令，最后用数据总线传输数据。</p><h2 id="4、线路位宽和cpu位宽"><a href="#4、线路位宽和cpu位宽" class="headerlink" title="4、线路位宽和cpu位宽"></a>4、线路位宽和cpu位宽</h2><p>地址总线：</p><p>想要 CPU 操作 4G 大的内存，那么就需要 32 条地址总线，因为 2 ^ 32 &#x3D; 4G。使通过线路能一次访问到所有的内存地址。</p><p>4G内存最好是32位宽的地址总线。</p><p>cpu位宽：</p><p>最好不要小于线路位宽</p><p>32位cpu最大只能操作4GB的内存，64位cpu理论可以寻址2^64</p><h2 id="5、cpu执行指令的流程："><a href="#5、cpu执行指令的流程：" class="headerlink" title="5、cpu执行指令的流程："></a>5、cpu执行指令的流程：</h2><p>先由<strong>程序计数器</strong>得到指令的地址，然后<strong>控制单元</strong>通过<strong>地址总线</strong>找到内存中的指令，由<strong>数据总线</strong>将指令传到<strong>指令寄存器</strong>中。</p><p>然后<strong>程序计数器</strong>自增，指向下一条指令，如果是32位cpu，指令是4字节，就自增4</p><p>然后分析<strong>指令寄存器</strong>中的指令，如果是计算类型，交由<strong>逻辑运算单元</strong>，如果是存储类型，交由<strong>控制单元</strong></p><h2 id="6、不同cpu有不同的指令集，即指令对应不同的汇编语言和机器码"><a href="#6、不同cpu有不同的指令集，即指令对应不同的汇编语言和机器码" class="headerlink" title="6、不同cpu有不同的指令集，即指令对应不同的汇编语言和机器码"></a>6、不同cpu有不同的指令集，即指令对应不同的汇编语言和机器码</h2><h3 id="1）以MIPS指集为例，指令是一个32位整数，高六位是操作码，表示是什么样的指令。"><a href="#1）以MIPS指集为例，指令是一个32位整数，高六位是操作码，表示是什么样的指令。" class="headerlink" title="1）以MIPS指集为例，指令是一个32位整数，高六位是操作码，表示是什么样的指令。"></a>1）以MIPS指集为例，指令是一个32位整数，高六位是操作码，表示是什么样的指令。</h3><h3 id="2）四级流水线："><a href="#2）四级流水线：" class="headerlink" title="2）四级流水线："></a>2）四级流水线：</h3><p>cpu将一个任务拆分为多个小任务，通常将一个指令分为4个阶段，称为<strong>4****级流水线</strong>。</p><p><strong>指令周期：Fetch（取得指令），Decode（指令译码）， Execution（执行指令），Store（数据回写）</strong></p><p>取指令和译码过程由控制器完成，执行一般由运算器完成，但如果是是简单地址跳转则依然是控制器。</p><h2 id="7、线程之间通信方式："><a href="#7、线程之间通信方式：" class="headerlink" title="7、线程之间通信方式："></a>7、线程之间通信方式：</h2><p>主要分为三个方式：<strong>共享内存、消息传递（通过<strong><strong>wait</strong></strong>，<strong><strong>notify</strong></strong>或<strong><strong>join</strong></strong>方法实现）、管道流</strong></p><h3 id="1）共享内存"><a href="#1）共享内存" class="headerlink" title="1）共享内存"></a>1）共享内存</h3><p>线程通过拷贝共享内存的副本进行内存共享：</p><p>这其中会有同步的问题，可以在变量前加<strong>volatile</strong>保证一个线程修改完该变量后，需要先将这个最新修改的值写回到主内存，从而保证下一个读取该变量的线程取得的就是主内存中该数据的最新值</p><h3 id="2）消息传递"><a href="#2）消息传递" class="headerlink" title="2）消息传递"></a>2）消息传递</h3><p><strong>Wait(),notify()</strong></p><p>线程a调用object对象的wait方法进入阻塞状态，线程b调用对象的notify(通知)方法解除a的阻塞状态。</p><p><strong>Join()</strong></p><p>当线程a调用线程b的join方法后，会让线程a阻塞，直到线程b的逻辑执行完成，a才会解除阻塞，继续执行自己的业务。</p><h3 id="3）管道流："><a href="#3）管道流：" class="headerlink" title="3）管道流："></a>3）管道流：</h3><p>管道流是是一种使用比较少的线程间通信方式，管道输入&#x2F;输出流和普通文件输入&#x2F;输出流或者网络输出&#x2F;输出流不同之处在于，它主要用于线程之间的数据传输，传输的媒介为管道。</p><p>管道输入&#x2F;输出流主要包括4种具体的实现：<strong>PipedOutputStrean、PipedInputStrean、PipedReader和PipedWriter</strong>，前两种面向字节，</p><p>后两种面向字符。</p>]]></content>
    
    
    
    <tags>
      
      <tag>知识分享</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis常见知识点</title>
    <link href="/2025/10/05/redis%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    <url>/2025/10/05/redis%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    
    <content type="html"><![CDATA[<h1 id="一、redis优于memcache的地方"><a href="#一、redis优于memcache的地方" class="headerlink" title="一、redis优于memcache的地方"></a>一、redis优于memcache的地方</h1><h2 id="1、redis支持多种数据结构："><a href="#1、redis支持多种数据结构：" class="headerlink" title="1、redis支持多种数据结构："></a>1、redis支持多种数据结构：</h2><p> 1）<strong>String</strong>: 主要用于缓存对象，计数，分布式锁</p><p>  2）<strong>哈希表</strong>：也是主要用于缓存对象，但还可以缓存购物车</p><p> 3）<strong>链表</strong>：主要缓存消息队列</p><p> 4）<strong>集合</strong>：适用于需要交并差运算的场景，比如点赞，共同关注，抽奖活动</p><p>  5）<strong>有序集合</strong>：主要用于排行榜，电话，姓名排序等</p><h2 id="2、redis支持数据持久化"><a href="#2、redis支持数据持久化" class="headerlink" title="2、redis支持数据持久化"></a>2、redis支持数据持久化</h2><h2 id="3、redis支持原生集群模式"><a href="#3、redis支持原生集群模式" class="headerlink" title="3、redis支持原生集群模式"></a>3、redis支持原生集群模式</h2><h2 id="4、redis支持发布订阅模型，lua脚本、事务等功能，而memcache不支持。"><a href="#4、redis支持发布订阅模型，lua脚本、事务等功能，而memcache不支持。" class="headerlink" title="4、redis支持发布订阅模型，lua脚本、事务等功能，而memcache不支持。"></a>4、redis支持发布订阅模型，lua脚本、事务等功能，而memcache不支持。</h2><p>  但这些数据结构都还只是表象，redis底层还有对于这些数据结构实现的数据结构。</p><p>  1）String底层使用<strong>int</strong>和<strong>SDS</strong>（动态字符串)实现,int类型的len存放字符串的长度。</p><p>  2）hash类型底层使用<strong>压缩列表</strong>或<strong>哈希表</strong>实现。</p><p>  3）List类型使用<strong>压缩列表</strong>或<strong>双向链表</strong>实现。</p><p>  4）集合Set类型使用<strong>整数集合</strong>或<strong>哈希表</strong>实现。</p><p>  5）有序集合ZSet使用<strong>哈希表</strong>或<strong>跳表</strong>实现。</p><h1 id="二、Redis单线程"><a href="#二、Redis单线程" class="headerlink" title="二、Redis单线程"></a>二、Redis单线程</h1><h2 id="1、定义："><a href="#1、定义：" class="headerlink" title="1、定义："></a>1、定义：</h2><p>指【接收客户端请求-》解析请求-》进行数据读写-》发送数据给客户端】这个过程是由一个线程（主线程）来完成的。</p><p>但这并不意味着redis程序是单线程的。</p><p>redis还有后台线程。</p><p>redis在2.6之后，启动两个后台线程，分别处理关闭文件，aof刷盘。</p><p>4.0之后，又新增了一个后台线程，用来异步释放redis内存，叫lazyfree线程。</p><h2 id="2、结构图"><a href="#2、结构图" class="headerlink" title="2、结构图"></a>2、结构图</h2><h2 id="3、为什么单线程依然很快？"><a href="#3、为什么单线程依然很快？" class="headerlink" title="3、为什么单线程依然很快？"></a>3、为什么单线程依然很快？</h2><p>1)大部分操作都在内存中完成，瓶颈一般是机器内存或带宽，并非cpu，既然cpu不是瓶颈，自然采用单线程。</p><p>2）避免多线程竞争</p><p>3）redis采用io多路复用</p><h2 id="4、redis在6-0后引入了多个线程来处理io请求，"><a href="#4、redis在6-0后引入了多个线程来处理io请求，" class="headerlink" title="4、redis在6.0后引入了多个线程来处理io请求，"></a>4、redis在6.0后引入了多个线程来处理io请求，</h2><p>因为随着网络硬件的性能提升，redis性能瓶颈有时出现在网络io处理上。</p><p>但是对于命令的执行依然是单线程。</p><h1 id="三、AOF部分："><a href="#三、AOF部分：" class="headerlink" title="三、AOF部分："></a>三、AOF部分：</h1><h2 id="1、redis三种aof数据写入磁盘策略：always-everysec-no"><a href="#1、redis三种aof数据写入磁盘策略：always-everysec-no" class="headerlink" title="1、redis三种aof数据写入磁盘策略：always, everysec, no"></a>1、redis三种aof数据写入磁盘策略：always, everysec, no</h2><h2 id="2、aof太大超过阈值会触发重写机制"><a href="#2、aof太大超过阈值会触发重写机制" class="headerlink" title="2、aof太大超过阈值会触发重写机制"></a>2、aof太大超过阈值会触发重写机制</h2><p>1)使用后台<strong>子进程</strong>bgrewriteaof来完成，因此主线程可以在这时继续处理命令。</p><p>   子进程与父进程共享内存数据，子进程会读取数据库中的所有数据，并逐一将键值对转化为一条条命令，所以可以很方便的根据内存中的键值对来进行aof文件压缩。</p><h2 id="3、进行aof重写时父进程继续执行命令，会导致父子进程的内存数据不一致"><a href="#3、进行aof重写时父进程继续执行命令，会导致父子进程的内存数据不一致" class="headerlink" title="3、进行aof重写时父进程继续执行命令，会导致父子进程的内存数据不一致"></a>3、进行aof重写时父进程继续执行命令，会导致父子进程的内存数据不一致</h2><p>为解决这个问题，引入了aof重写缓冲区。在子进程完成aof重写后，会告诉主进程，让它调用一个函数，将aof重写缓冲区的所有内容追加到aof文件中去。</p><h1 id="四、RDB部分"><a href="#四、RDB部分" class="headerlink" title="四、RDB部分"></a>四、RDB部分</h1><h2 id="1、因为aof恢复数据是将日志重新执行一遍，所以比rdb快照式的恢复数据要慢一些。"><a href="#1、因为aof恢复数据是将日志重新执行一遍，所以比rdb快照式的恢复数据要慢一些。" class="headerlink" title="1、因为aof恢复数据是将日志重新执行一遍，所以比rdb快照式的恢复数据要慢一些。"></a>1、因为aof恢复数据是将日志重新执行一遍，所以比rdb快照式的恢复数据要慢一些。</h2><h2 id="2、如何生成RDB文件"><a href="#2、如何生成RDB文件" class="headerlink" title="2、如何生成RDB文件"></a>2、如何生成RDB文件</h2><p>Redis 提供了两个命令来生成 RDB 文件，分别是 <strong>save</strong> 和 <strong>bgsave</strong>，他们的区别就在于<strong>是否在「主线程」里执行</strong>：</p><p>1）执行save，会由主线程生成rdb文件，写入时间太长就会阻塞主线程。</p><p>2）执行bgsave，由子线程生成</p><p>主子进程通过复制页表操作同一块物理内存。</p><p>通过修改配置文件调整rdb的快照频率</p><h2 id="3、混合持久化："><a href="#3、混合持久化：" class="headerlink" title="3、混合持久化："></a>3、混合持久化：</h2><p>1、使用混合持久化，aof的前半部分是rdb格式的全量数据，后半部分是aof的增量数据。</p><h1 id="五、Redis集群cluster"><a href="#五、Redis集群cluster" class="headerlink" title="五、Redis集群cluster"></a>五、Redis集群cluster</h1><h2 id="1、如何实现高可用？"><a href="#1、如何实现高可用？" class="headerlink" title="1、如何实现高可用？"></a>1、如何实现高可用？</h2><p>所有数据修改只在主服务器进行，然后将最新数据同步给从服务器，保持主从一致。</p><h2 id="2、切片集群模式："><a href="#2、切片集群模式：" class="headerlink" title="2、切片集群模式："></a>2、切片集群模式：</h2><p>数据量太大，需要分布到不同的服务器上。</p><p>一个切片集群有16384个哈希槽slot，对于每一个键值对的key，使用crc16算法计算16bit的值，然后对16384取模。</p><p>将这16384个slot平均或手动分配到redis实例上</p><h2 id="3、集群脑裂"><a href="#3、集群脑裂" class="headerlink" title="3、集群脑裂"></a>3、集群脑裂</h2><h3 id="1）定义"><a href="#1）定义" class="headerlink" title="1）定义"></a>1）定义</h3><p>由于网络问题，主节点与其他从节点失去联系，哨兵会选出新的主节点，网络恢复后原先的主节点会降级为从节点并从新的主节点处拷贝数据，在网络失效的这段时间里，客户端向原先主节点写入的数据就会失效。</p><h3 id="2）解决方式："><a href="#2）解决方式：" class="headerlink" title="2）解决方式："></a>2）解决方式：</h3><p>当主节点发现从节点下线，联系不到，就禁止主节点进行写数据，直接把错误返回客户端。</p><p>min-slaves-to-write x ：至少x个从节点连接</p><p>min-slaves-max-lag  x ：主从节点延时不超过x秒</p><h1 id="六、过期键的处理"><a href="#六、过期键的处理" class="headerlink" title="六、过期键的处理"></a>六、过期键的处理</h1><h2 id="1、惰性删除和定期删除"><a href="#1、惰性删除和定期删除" class="headerlink" title="1、惰性删除和定期删除"></a>1、惰性删除和定期删除</h2><h2 id="2、持久化时对过期键的处理"><a href="#2、持久化时对过期键的处理" class="headerlink" title="2、持久化时对过期键的处理"></a>2、持久化时对过期键的处理</h2><h2 id="3、主从模式下对过期键的处理"><a href="#3、主从模式下对过期键的处理" class="headerlink" title="3、主从模式下对过期键的处理"></a>3、主从模式下对过期键的处理</h2><h1 id="七、内存满了，内存淘汰策略"><a href="#七、内存满了，内存淘汰策略" class="headerlink" title="七、内存满了，内存淘汰策略"></a>七、内存满了，内存淘汰策略</h1><h2 id="1、不进行数据淘汰的策略：noeviction-3-0之后的默认策略"><a href="#1、不进行数据淘汰的策略：noeviction-3-0之后的默认策略" class="headerlink" title="1、不进行数据淘汰的策略：noeviction(3.0之后的默认策略)"></a>1、不进行数据淘汰的策略：noeviction(3.0之后的默认策略)</h2><h2 id="2、进行数据淘汰：七种"><a href="#2、进行数据淘汰：七种" class="headerlink" title="2、进行数据淘汰：七种"></a>2、进行数据淘汰：七种</h2><p>redis自己的lru算法：随机抽五个，淘汰其中最久没被使用的</p><p>lru和lfu都是在redis对象头中定义一个24bit的字段来存储时间戳和访问频率</p><h1 id="八、缓存雪崩，击穿，穿透"><a href="#八、缓存雪崩，击穿，穿透" class="headerlink" title="八、缓存雪崩，击穿，穿透"></a>八、缓存雪崩，击穿，穿透</h1><h2 id="1、雪崩指redis宕机或同时大量的key过期。"><a href="#1、雪崩指redis宕机或同时大量的key过期。" class="headerlink" title="1、雪崩指redis宕机或同时大量的key过期。"></a>1、雪崩指redis宕机或同时大量的key过期。</h2><h2 id="2、击穿指某个热点的key过期。"><a href="#2、击穿指某个热点的key过期。" class="headerlink" title="2、击穿指某个热点的key过期。"></a>2、击穿指某个热点的key过期。</h2><h2 id="3、穿透指查询不存在的数据。"><a href="#3、穿透指查询不存在的数据。" class="headerlink" title="3、穿透指查询不存在的数据。"></a>3、穿透指查询不存在的数据。</h2><h1 id="九、缓存更新策略（当数据库发生修改，需要对缓存进行更新）"><a href="#九、缓存更新策略（当数据库发生修改，需要对缓存进行更新）" class="headerlink" title="九、缓存更新策略（当数据库发生修改，需要对缓存进行更新）"></a>九、缓存更新策略（当数据库发生修改，需要对缓存进行更新）</h1><h2 id="1、Cache-aside策略：黑马讲的策略，先更新数据库，再删除缓存。"><a href="#1、Cache-aside策略：黑马讲的策略，先更新数据库，再删除缓存。" class="headerlink" title="1、Cache aside策略：黑马讲的策略，先更新数据库，再删除缓存。"></a>1、Cache aside策略：黑马讲的策略，先更新数据库，再删除缓存。</h2><h2 id="2、读穿-写穿策略：应用程序只和缓存交互"><a href="#2、读穿-写穿策略：应用程序只和缓存交互" class="headerlink" title="2、读穿&#x2F;写穿策略：应用程序只和缓存交互"></a>2、读穿&#x2F;写穿策略：应用程序只和缓存交互</h2><p>Read through：查询缓存中是否存在，存在则直接返回；不存在，则由缓存负责从数据库查数据，将结果再写入缓存，最后返回给客户端。</p><p>Write through：写入数据时先查询要写入的数据是否已存在，</p><p>若已存在，则更新缓存中的数据，再由缓存更新到数据库中。</p><p>若不存在，则直接更新数据库。</p><p>这种策略一般在使用本地缓存中考虑，因为redis和memcached不支持。</p><h2 id="3、写回策略（write-back）"><a href="#3、写回策略（write-back）" class="headerlink" title="3、写回策略（write back）"></a>3、写回策略（write back）</h2><p>写时只更新缓存，同时将缓存数据设置为脏，然后立马返回。</p><p>对于数据库的更新，使用批量异步更新的方式。</p><p>写回策略也很少用于redis中，因为redis无法异步更新数据库。写回策略主要用在cpu缓存，文件系统缓存。</p><h1 id="十、redis实现延迟队列"><a href="#十、redis实现延迟队列" class="headerlink" title="十、redis实现延迟队列"></a>十、redis实现延迟队列</h1><p>把当前要做的事，推迟一段时间再做</p><p>使用有序队列zset来实现，其中<strong>score</strong>属性（权重）存储延迟执行的时间。</p><p>使用zadd score1 value1 命令往内存中生产消息，再用zrangebysocre查询待处理任务。</p><h1 id="十一、大key如何处理-value很大的key"><a href="#十一、大key如何处理-value很大的key" class="headerlink" title="十一、大key如何处理(value很大的key)"></a>十一、大key如何处理(value很大的key)</h1><h2 id="1、查找大key"><a href="#1、查找大key" class="headerlink" title="1、查找大key"></a>1、查找大key</h2><p>1)通过 redis-cli –bigkeys 命令，并做好在从节点上执行，但只能返回每种类型中最大的bigkey</p><p>2)使用SCAN命令扫描数据库</p><p>3)使用rdbtools第三方开源工具解析redis快照rdb文件，找到大key。</p><h2 id="2、删除内存中的key"><a href="#2、删除内存中的key" class="headerlink" title="2、删除内存中的key"></a>2、删除内存中的key</h2><p>在删除过程中，需要把释放掉的内存块插入空闲内存块的链表，这个过程会消耗一定时间。</p><p>解决方式：</p><p>1、<strong>分批次删</strong>，但还是在主线程中</p><p>2、<strong>异步删除</strong>，用unlink代替del，将key放入一个异步线程中删除。即lazyfree线程。</p><h1 id="十二、redis管道（pipeline）"><a href="#十二、redis管道（pipeline）" class="headerlink" title="十二、redis管道（pipeline）"></a>十二、redis管道（pipeline）</h1><p>客户端提供的批处理技术，一次处理多个 Redis 命令，将多个命令打包一起发送给服务器端。</p><h1 id="十三、redis没有事务运行错误回滚，不支持事务原子性"><a href="#十三、redis没有事务运行错误回滚，不支持事务原子性" class="headerlink" title="十三、redis没有事务运行错误回滚，不支持事务原子性"></a>十三、redis没有事务运行错误回滚，不支持事务原子性</h1><h2 id="1、原因"><a href="#1、原因" class="headerlink" title="1、原因"></a>1、原因</h2><p>因为作者认为<strong>加回滚会损失性能</strong>，而且错误一般是编程错误导致。</p><h2 id="2、解决方式："><a href="#2、解决方式：" class="headerlink" title="2、解决方式："></a>2、解决方式：</h2><p>1）使用lua脚本</p><h1 id="十四、用redis实现分布式锁"><a href="#十四、用redis实现分布式锁" class="headerlink" title="十四、用redis实现分布式锁"></a>十四、用redis实现分布式锁</h1><h2 id="1、set命令的nx参数实现key不存在才插入，可以用它实现分布式锁，"><a href="#1、set命令的nx参数实现key不存在才插入，可以用它实现分布式锁，" class="headerlink" title="1、set命令的nx参数实现key不存在才插入，可以用它实现分布式锁，"></a>1、set命令的nx参数实现key不存在才插入，可以用它实现分布式锁，</h2><p>如果key不存在，则插入成功，表示加锁成功</p><p>如果key存在，则插入失败，表示加锁失败</p><h3 id="1）加解锁指令："><a href="#1）加解锁指令：" class="headerlink" title="1）加解锁指令："></a>1）加解锁指令：</h3><p>SET lock_key unique_value NX PX 10000</p><p>Unique_value标识客户端，PX设置过期时间10s。</p><p>解锁的时候需要先判断执行操作的客户端是否是unique_value对应的客户端。</p><p>解锁时的原子性可以由lua脚本保证，lua脚本在redis执行是保证原子性的。</p><h2 id="2、优缺点"><a href="#2、优缺点" class="headerlink" title="2、优缺点"></a>2、优缺点</h2><p>使用redis实现分布式锁的</p><p>优点：1、性能高，2、实现方便，3、避免单点故障（跨集群部署）</p><p>缺点：1、超时时间不好设置，2、主从复制是异步的，导致分布式锁<strong>不可靠</strong>。</p><h2 id="3、为了保证可靠性，官方设计分布式锁算法redlock红锁"><a href="#3、为了保证可靠性，官方设计分布式锁算法redlock红锁" class="headerlink" title="3、为了保证可靠性，官方设计分布式锁算法redlock红锁"></a>3、为了保证可靠性，官方设计分布式锁算法redlock红锁</h2><p>它是多节点的锁，让客户端和多个独立的redis节点依次请求加锁，若半数以上能成功，就认为加锁成功。</p>]]></content>
    
    
    
    <tags>
      
      <tag>知识分享</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第一篇博客</title>
    <link href="/2024/12/10/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
    <url>/2024/12/10/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h2 id="第一篇博客"><a href="#第一篇博客" class="headerlink" title="第一篇博客"></a>第一篇博客</h2><p>这是我的第一篇发表在个人博客网站上的博客，我想用它来测试功能，并展示我是如何搭建起博客网站的。</p><h3 id="我搭建网站参考的博客："><a href="#我搭建网站参考的博客：" class="headerlink" title="我搭建网站参考的博客："></a>我搭建网站参考的博客：</h3><p><a href="https://blog.csdn.net/yaorongke/article/details/119089190">GitHub Pages + Hexo搭建个人博客网站，史上最全教程_hexo博客-CSDN博客</a></p><p>其中也碰了壁：</p><p>1、使用leanCloud得用国际版，国内版得备案</p><p>2、图片无法展示</p>]]></content>
    
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
